import asyncio
from datetime import datetime, timedelta
import logging
from src.database.database import init_db, get_source_db, get_destination_db
from src.database.realState import transfer_from_withagence_to_finale

logger = logging.getLogger(__name__)

async def process_and_transfer_images(instances: int = 5) -> None:
    """Traite et transf√®re les annonces en continu avec plusieurs instances, v√©rifie toutes les heures."""
    logger.info(f"üöÄ D√©but du traitement continu des images avec {instances} instances...")
    try:
        await init_db()
        logger.info("‚úÖ Base de donn√©es initialis√©e avec succ√®s.")
    except Exception as e:
        logger.error(f"‚ùå √âchec de l'initialisation de la base de donn√©es: {e}")
        return

    # Lancer les instances en parall√®le
    tasks = [process_instance(i) for i in range(instances)]
    await asyncio.gather(*tasks)

async def process_instance(instance_id: int) -> None:
    """Instance individuelle de traitement des annonces avec v√©rification horaire."""
    source_db = get_source_db()
    dest_db = get_destination_db()
    last_check = datetime.now() - timedelta(hours=1)  # Forcer la premi√®re v√©rification

    while True:
        try:
            current_time = datetime.now()
            if (current_time - last_check).total_seconds() >= 3600:  # V√©rifier toutes les heures
                logger.info(f"‚è∞ Instance {instance_id} : V√©rification horaire des nouvelles annonces.")
                last_check = current_time

            # R√©cup√©rer les annonces √©ligibles (avec images valides, non trait√©es, pas dans finale)
            finale_ids = await dest_db["realStateFinale"].distinct("idSec")
            query = {
                "idAgence": {"$exists": True},
                "images": {
                    "$exists": True,
                    "$ne": [],
                    "$nin": [[], ["N/A"]],  # Exclure annonces sans images ou avec uniquement "N/A"
                },
                "processed": {"$ne": True},
                "idSec": {"$nin": finale_ids}
            }
            batch_size = 20  # Traiter par lots de 20 pour plus de rapidit√©
            annonces = await source_db["realStateWithAgence"].find(query).limit(batch_size).to_list(length=None)

            if not annonces:
                logger.debug(f"‚è≥ Instance {instance_id} : Aucune annonce √† traiter, attente de 10 secondes.")
                await asyncio.sleep(10)
                continue

            # Traitement parall√®le des annonces dans le lot
            tasks = [transfer_from_withagence_to_finale(annonce) for annonce in annonces]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            for annonce, result in zip(annonces, results):
                annonce_id = annonce["idSec"]
                if isinstance(result, Exception):
                    logger.error(f"‚ö†Ô∏è Instance {instance_id} : Erreur pour {annonce_id}: {result}")
                    continue
                if not result["skipped"]:
                    logger.info(f"‚úÖ Instance {instance_id} : Annonce {annonce_id} transf√©r√©e.")
                    await source_db["realStateWithAgence"].update_one(
                        {"idSec": annonce_id},
                        {"$set": {"processed": True, "processed_at": datetime.utcnow()}}
                    )
                else:
                    logger.info(f"‚ÑπÔ∏è Instance {instance_id} : Annonce {annonce_id} non transf√©r√©e (images invalides ou d√©j√† pr√©sente).")

            await asyncio.sleep(1)  # Pause entre lots pour √©viter surcharge

        except Exception as e:
            logger.error(f"‚ö†Ô∏è Instance {instance_id} : Erreur dans la boucle: {e}")
            await asyncio.sleep(10)  # Attendre avant de r√©essayer

if __name__ == "__main__":
    asyncio.run(process_and_transfer_images())